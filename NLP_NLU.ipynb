{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "930c90d9-3ea2-4850-aed8-a21581027ea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnltk\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43mnltk\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdownload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\nltk\\downloader.py:748\u001b[39m, in \u001b[36mDownloader.download\u001b[39m\u001b[34m(self, info_or_id, download_dir, quiet, force, prefix, halt_on_error, raise_on_error, print_error_to)\u001b[39m\n\u001b[32m    746\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m download_dir \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    747\u001b[39m         \u001b[38;5;28mself\u001b[39m._download_dir = download_dir\n\u001b[32m--> \u001b[39m\u001b[32m748\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_interactive_download\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    751\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    752\u001b[39m     \u001b[38;5;66;03m# Define a helper function for displaying output:\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\nltk\\downloader.py:1112\u001b[39m, in \u001b[36mDownloader._interactive_download\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1109\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m   1111\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1112\u001b[39m     \u001b[43mDownloaderGUI\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmainloop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1113\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m tkinter.TclError:\n\u001b[32m   1114\u001b[39m     DownloaderShell(\u001b[38;5;28mself\u001b[39m).run()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\nltk\\downloader.py:1960\u001b[39m, in \u001b[36mDownloaderGUI.mainloop\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1959\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmainloop\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m-> \u001b[39m\u001b[32m1960\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmainloop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\tkinter\\__init__.py:1599\u001b[39m, in \u001b[36mMisc.mainloop\u001b[39m\u001b[34m(self, n)\u001b[39m\n\u001b[32m   1597\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmainloop\u001b[39m(\u001b[38;5;28mself\u001b[39m, n=\u001b[32m0\u001b[39m):\n\u001b[32m   1598\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Call the mainloop of Tk.\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1599\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtk\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmainloop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import nltk\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ce77cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Downloading nltk-3.9.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: click in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from nltk) (8.1.8)\n",
      "Requirement already satisfied: joblib in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from nltk) (1.5.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from nltk) (2025.9.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\dell\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Downloading nltk-3.9.2-py3-none-any.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.5/1.5 MB 9.2 MB/s  0:00:00\n",
      "Installing collected packages: nltk\n",
      "Successfully installed nltk-3.9.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~oogle-ai-generativelanguage (c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~penai (c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~oogle-ai-generativelanguage (c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~penai (c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~oogle-ai-generativelanguage (c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~penai (c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084b3bf3-aeb3-4220-bf98-affdbf7052cb",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nltk'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnltk\u001b[39;00m\n\u001b[32m      2\u001b[39m nltk.download(\u001b[33m'\u001b[39m\u001b[33mpunkt\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      3\u001b[39m nltk.download(\u001b[33m'\u001b[39m\u001b[33mpunkt_tab\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'nltk'"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75a71fef-8410-4c12-bfe9-e531b2be2a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "AI = '''Artificial Intelligence refers to the intelligence of machines. This is in contrast to the natural intelligence of\n",
    "humans and animals. With Artificial Intelligence, machines perform functions such as learning, planning, reasoning and\n",
    "problem-solving. Most noteworthy, Artificial Intelligence is the simulation of human intelligence by machines.\n",
    "It is probably the fastest-growing development in the World of technology and innovation. Furthermore, many experts believe\n",
    "AI could solve major challenges and crisis situations.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "363bbef3-a138-4e31-b088-b77275f679a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Artificial Intelligence refers to the intelligence of machines. This is in contrast to the natural intelligence of\\nhumans and animals. With Artificial Intelligence, machines perform functions such as learning, planning, reasoning and\\nproblem-solving. Most noteworthy, Artificial Intelligence is the simulation of human intelligence by machines.\\nIt is probably the fastest-growing development in the World of technology and innovation. Furthermore, many experts believe\\nAI could solve major challenges and crisis situations.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d66ad55a-90f4-4676-b103-d19ac2ae22db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(AI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a29fd349-2b46-476e-a213-aba3d921df74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e77f3f9-5e6e-4d2f-a14d-0162ee23981d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Artificial',\n",
       " 'Intelligence',\n",
       " 'refers',\n",
       " 'to',\n",
       " 'the',\n",
       " 'intelligence',\n",
       " 'of',\n",
       " 'machines',\n",
       " '.',\n",
       " 'This',\n",
       " 'is',\n",
       " 'in',\n",
       " 'contrast',\n",
       " 'to',\n",
       " 'the',\n",
       " 'natural',\n",
       " 'intelligence',\n",
       " 'of',\n",
       " 'humans',\n",
       " 'and',\n",
       " 'animals',\n",
       " '.',\n",
       " 'With',\n",
       " 'Artificial',\n",
       " 'Intelligence',\n",
       " ',',\n",
       " 'machines',\n",
       " 'perform',\n",
       " 'functions',\n",
       " 'such',\n",
       " 'as',\n",
       " 'learning',\n",
       " ',',\n",
       " 'planning',\n",
       " ',',\n",
       " 'reasoning',\n",
       " 'and',\n",
       " 'problem-solving',\n",
       " '.',\n",
       " 'Most',\n",
       " 'noteworthy',\n",
       " ',',\n",
       " 'Artificial',\n",
       " 'Intelligence',\n",
       " 'is',\n",
       " 'the',\n",
       " 'simulation',\n",
       " 'of',\n",
       " 'human',\n",
       " 'intelligence',\n",
       " 'by',\n",
       " 'machines',\n",
       " '.',\n",
       " 'It',\n",
       " 'is',\n",
       " 'probably',\n",
       " 'the',\n",
       " 'fastest-growing',\n",
       " 'development',\n",
       " 'in',\n",
       " 'the',\n",
       " 'World',\n",
       " 'of',\n",
       " 'technology',\n",
       " 'and',\n",
       " 'innovation',\n",
       " '.',\n",
       " 'Furthermore',\n",
       " ',',\n",
       " 'many',\n",
       " 'experts',\n",
       " 'believe',\n",
       " 'AI',\n",
       " 'could',\n",
       " 'solve',\n",
       " 'major',\n",
       " 'challenges',\n",
       " 'and',\n",
       " 'crisis',\n",
       " 'situations',\n",
       " '.']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AI_tokens = word_tokenize(AI)\n",
    "AI_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37923cbe-a9cd-44a9-853c-e319b82f8d7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(AI_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26923aca-d07c-4b16-b5c9-dc1cab1a184b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Artificial Intelligence refers to the intelligence of machines. This is in contrast to the natural intelligence of\\nhumans and animals. With Artificial Intelligence, machines perform functions such as learning, planning, reasoning and\\nproblem-solving. Most noteworthy, Artificial Intelligence is the simulation of human intelligence by machines.\\nIt is probably the fastest-growing development in the World of technology and innovation. Furthermore, many experts believe\\nAI could solve major challenges and crisis situations.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd433d90-cd5b-4034-a178-1f88c9e9aba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17ab52c0-0414-4032-a703-0a7348d6ba28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Artificial Intelligence refers to the intelligence of machines.',\n",
       " 'This is in contrast to the natural intelligence of\\nhumans and animals.',\n",
       " 'With Artificial Intelligence, machines perform functions such as learning, planning, reasoning and\\nproblem-solving.',\n",
       " 'Most noteworthy, Artificial Intelligence is the simulation of human intelligence by machines.',\n",
       " 'It is probably the fastest-growing development in the World of technology and innovation.',\n",
       " 'Furthermore, many experts believe\\nAI could solve major challenges and crisis situations.']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AI_sent = sent_tokenize(AI)\n",
    "AI_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71fc5df1-65e2-40d1-a918-357bf211fc14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(AI_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030578dd-3415-4e1c-9499-ecf29cf4790f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Artificial Intelligence refers to the intelligence of machines. This is in contrast to the natural intelligence of\\nhumans and animals. With Artificial Intelligence, machines perform functions such as learning, planning, reasoning and\\nproblem-solving. Most noteworthy, Artificial Intelligence is the simulation of human intelligence by machines.\\nIt is probably the fastest-growing development in the World of technology and innovation. Furthermore, many experts believe\\nAI could solve major challenges and crisis situations.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b198611-13b4-4b02-a9b3-a4b9086a3b63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Artificial Intelligence refers to the intelligence of machines. This is in contrast to the natural intelligence of\\nhumans and animals. With Artificial Intelligence, machines perform functions such as learning, planning, reasoning and\\nproblem-solving. Most noteworthy, Artificial Intelligence is the simulation of human intelligence by machines.\\nIt is probably the fastest-growing development in the World of technology and innovation. Furthermore, many experts believe\\nAI could solve major challenges and crisis situations.']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import blankline_tokenize #give how many paragraphs\n",
    "AI_blank = blankline_tokenize(AI)\n",
    "AI_blank"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4418cc4-8c0d-4ed7-9055-ace83066fb42",
   "metadata": {},
   "source": [
    "# Whitespace Tokenization\n",
    "Definition: Splits text based on whitespace (spaces, tabs, newlines) without removing punctuation.\n",
    "• Useful when punctuation should be preserved as part of the tokens.\n",
    "• Faster but less precise than other tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01874b8-0eac-4f3c-af24-a0678755da82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Artificial',\n",
       " 'Intelligence',\n",
       " 'refers',\n",
       " 'to',\n",
       " 'the',\n",
       " 'intelligence',\n",
       " 'of',\n",
       " 'machines.',\n",
       " 'This',\n",
       " 'is',\n",
       " 'in',\n",
       " 'contrast',\n",
       " 'to',\n",
       " 'the',\n",
       " 'natural',\n",
       " 'intelligence',\n",
       " 'of',\n",
       " 'humans',\n",
       " 'and',\n",
       " 'animals.',\n",
       " 'With',\n",
       " 'Artificial',\n",
       " 'Intelligence,',\n",
       " 'machines',\n",
       " 'perform',\n",
       " 'functions',\n",
       " 'such',\n",
       " 'as',\n",
       " 'learning,',\n",
       " 'planning,',\n",
       " 'reasoning',\n",
       " 'and',\n",
       " 'problem-solving.',\n",
       " 'Most',\n",
       " 'noteworthy,',\n",
       " 'Artificial',\n",
       " 'Intelligence',\n",
       " 'is',\n",
       " 'the',\n",
       " 'simulation',\n",
       " 'of',\n",
       " 'human',\n",
       " 'intelligence',\n",
       " 'by',\n",
       " 'machines.',\n",
       " 'It',\n",
       " 'is',\n",
       " 'probably',\n",
       " 'the',\n",
       " 'fastest-growing',\n",
       " 'development',\n",
       " 'in',\n",
       " 'the',\n",
       " 'World',\n",
       " 'of',\n",
       " 'technology',\n",
       " 'and',\n",
       " 'innovation.',\n",
       " 'Furthermore,',\n",
       " 'many',\n",
       " 'experts',\n",
       " 'believe',\n",
       " 'AI',\n",
       " 'could',\n",
       " 'solve',\n",
       " 'major',\n",
       " 'challenges',\n",
       " 'and',\n",
       " 'crisis',\n",
       " 'situations.']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "wt = WhitespaceTokenizer().tokenize(AI)\n",
    "wt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895aa6c5-2f80-48c4-9c5e-2b25c5551a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70\n"
     ]
    }
   ],
   "source": [
    "print(len(wt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5993589d-e88f-4ece-9f9a-6a44dd15771d",
   "metadata": {},
   "outputs": [],
   "source": [
    "s='Good apple cost $3.88 in hyderbad.please buy two of them.Thanks.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5853299e-59da-477b-8790-e00ff219d63b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Good apple cost $3.88 in hyderbad.please buy two of them.Thanks.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6edb9c5-7ade-415a-a341-83161aa8d4f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Good',\n",
       " 'apple',\n",
       " 'cost',\n",
       " '$',\n",
       " '3',\n",
       " '.',\n",
       " '88',\n",
       " 'in',\n",
       " 'hyderbad',\n",
       " '.',\n",
       " 'please',\n",
       " 'buy',\n",
       " 'two',\n",
       " 'of',\n",
       " 'them',\n",
       " '.',\n",
       " 'Thanks',\n",
       " '.']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import wordpunct_tokenize\n",
    "wordpunct_tokenize(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816e850a-b4d5-43db-bc7e-c653848f9fa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Artificial',\n",
       " 'Intelligence',\n",
       " 'refers',\n",
       " 'to',\n",
       " 'the',\n",
       " 'intelligence',\n",
       " 'of',\n",
       " 'machines',\n",
       " '.',\n",
       " 'This',\n",
       " 'is',\n",
       " 'in',\n",
       " 'contrast',\n",
       " 'to',\n",
       " 'the',\n",
       " 'natural',\n",
       " 'intelligence',\n",
       " 'of',\n",
       " 'humans',\n",
       " 'and',\n",
       " 'animals',\n",
       " '.',\n",
       " 'With',\n",
       " 'Artificial',\n",
       " 'Intelligence',\n",
       " ',',\n",
       " 'machines',\n",
       " 'perform',\n",
       " 'functions',\n",
       " 'such',\n",
       " 'as',\n",
       " 'learning',\n",
       " ',',\n",
       " 'planning',\n",
       " ',',\n",
       " 'reasoning',\n",
       " 'and',\n",
       " 'problem',\n",
       " '-',\n",
       " 'solving',\n",
       " '.',\n",
       " 'Most',\n",
       " 'noteworthy',\n",
       " ',',\n",
       " 'Artificial',\n",
       " 'Intelligence',\n",
       " 'is',\n",
       " 'the',\n",
       " 'simulation',\n",
       " 'of',\n",
       " 'human',\n",
       " 'intelligence',\n",
       " 'by',\n",
       " 'machines',\n",
       " '.',\n",
       " 'It',\n",
       " 'is',\n",
       " 'probably',\n",
       " 'the',\n",
       " 'fastest',\n",
       " '-',\n",
       " 'growing',\n",
       " 'development',\n",
       " 'in',\n",
       " 'the',\n",
       " 'World',\n",
       " 'of',\n",
       " 'technology',\n",
       " 'and',\n",
       " 'innovation',\n",
       " '.',\n",
       " 'Furthermore',\n",
       " ',',\n",
       " 'many',\n",
       " 'experts',\n",
       " 'believe',\n",
       " 'AI',\n",
       " 'could',\n",
       " 'solve',\n",
       " 'major',\n",
       " 'challenges',\n",
       " 'and',\n",
       " 'crisis',\n",
       " 'situations',\n",
       " '.']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_p=wordpunct_tokenize(AI)\n",
    "w_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83dd7d39-c5c1-4ad8-9d07-1b1a207c9fe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(w_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5b3ccf-873d-452b-ba97-ddd2abcb1a46",
   "metadata": {},
   "source": [
    "# Function / Tokenizer Description\n",
    "-->word_tokenize Splits text into words and punctuation (accurate).\n",
    "-->sent_tokenize Splits text into sentences.\n",
    "-->blankline_tokenize Splits text into paragraphs by blank lines.\n",
    "-->WhitespaceTokenizer Splits by spaces/tabs only, keeps punctuation attached.\n",
    "-->wordpunct_tokenize Splits words and punctuation into separate tokens.\n",
    "-->pos_tag Assigns grammatical roles (nouns, verbs, adjectives) to each token.\n",
    "-->ne_chunk Performs Named Entity Recognition (NER) to identify people, places"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6135101-259c-4d37-8b1f-c56d56ca4522",
   "metadata": {},
   "source": [
    "# 3 N-grams\n",
    "Definition: Sequences of n consecutive tokens.\n",
    "• Bigram: 2-word sequence.\n",
    "• Trigram: 3-word sequence.\n",
    "• N-gram: Any n-word sequence (n > 3).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2042dabd-cd76-4a1d-968e-c621f72b6f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc685c4a-c428-47c1-b0dd-3ef535e09467",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.util import bigrams,trigrams,ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7daa3b-a1ad-4590-be0a-a4b51f085c16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Technology',\n",
       " 'is',\n",
       " 'becoming',\n",
       " 'an',\n",
       " 'important',\n",
       " 'part',\n",
       " 'of',\n",
       " 'our',\n",
       " 'daily',\n",
       " 'lives',\n",
       " '.']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string = \"Technology is becoming an important part of our daily lives.\"\n",
    "quotes_tokens =nltk.word_tokenize(string)\n",
    "quotes_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd57ab1c-0482-422d-b340-bf54904be17e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Technology is becoming an important part of our daily lives.'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65381275-320d-4467-b3fa-6781f138c825",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Technology',\n",
       " 'is',\n",
       " 'becoming',\n",
       " 'an',\n",
       " 'important',\n",
       " 'part',\n",
       " 'of',\n",
       " 'our',\n",
       " 'daily',\n",
       " 'lives',\n",
       " '.']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quotes_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eddeda6-9093-42fa-863a-d838814478d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(quotes_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e86f218-11ec-4203-8ba9-145c7ad4f03e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Technology', 'is'),\n",
       " ('is', 'becoming'),\n",
       " ('becoming', 'an'),\n",
       " ('an', 'important'),\n",
       " ('important', 'part'),\n",
       " ('part', 'of'),\n",
       " ('of', 'our'),\n",
       " ('our', 'daily'),\n",
       " ('daily', 'lives'),\n",
       " ('lives', '.')]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quotes_bigrams = list(nltk.bigrams(quotes_tokens))\n",
    "quotes_bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c160d2ad-f619-49d3-af6e-c19e7a307adb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Technology',\n",
       " 'is',\n",
       " 'becoming',\n",
       " 'an',\n",
       " 'important',\n",
       " 'part',\n",
       " 'of',\n",
       " 'our',\n",
       " 'daily',\n",
       " 'lives',\n",
       " '.']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quotes_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6ccee0-4ed0-444d-a238-6a6180340669",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Technology', 'is', 'becoming'),\n",
       " ('is', 'becoming', 'an'),\n",
       " ('becoming', 'an', 'important'),\n",
       " ('an', 'important', 'part'),\n",
       " ('important', 'part', 'of'),\n",
       " ('part', 'of', 'our'),\n",
       " ('of', 'our', 'daily'),\n",
       " ('our', 'daily', 'lives'),\n",
       " ('daily', 'lives', '.')]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quotes_trigrams = list(nltk.trigrams(quotes_tokens))\n",
    "quotes_trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1837679c-4ff0-4ead-8146-a66a0646d964",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ngrams() missing 1 required positional argument: 'n'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[42]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m quotes_ngrams = \u001b[38;5;28mlist\u001b[39m(\u001b[43mnltk\u001b[49m\u001b[43m.\u001b[49m\u001b[43mngrams\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquotes_tokens\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m      2\u001b[39m quotes_ngrams\n",
      "\u001b[31mTypeError\u001b[39m: ngrams() missing 1 required positional argument: 'n'"
     ]
    }
   ],
   "source": [
    "quotes_ngrams = list(nltk.ngrams(quotes_tokens))\n",
    "quotes_ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3bbc58-d988-429c-bfed-df59623af905",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Technology', 'is', 'becoming', 'an'),\n",
       " ('is', 'becoming', 'an', 'important'),\n",
       " ('becoming', 'an', 'important', 'part'),\n",
       " ('an', 'important', 'part', 'of'),\n",
       " ('important', 'part', 'of', 'our'),\n",
       " ('part', 'of', 'our', 'daily'),\n",
       " ('of', 'our', 'daily', 'lives'),\n",
       " ('our', 'daily', 'lives', '.')]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quotes_ngrams = list(nltk.ngrams(quotes_tokens,4))\n",
    "quotes_ngrams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4933645-db7c-4890-86dd-3ca0cd57a4cd",
   "metadata": {},
   "source": [
    "# stemming\n",
    "--> Reduces words to their root from ,often by chopping off suffixes.types\n",
    "--> porter stemmer - basic and widely used,but may not handle all words well.\n",
    "--> Lancaster Stemmer- more aggressive,sometimes overstems words.\n",
    "--> Snowball stemmer - Advanced,supports multiple languages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52318d4-a16a-46e3-a96f-63ffaff1dfce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer,LancasterStemmer, SnowballStemmer\n",
    "words_to_stem=['given','give','giving','gave','thinking','loving','maximum','gaved','sandhya']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0917fe70-4970-4903-bd83-7765e066005c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "pst = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32610fa1-a0db-4319-afc1-9dd69afaea1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'affect'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pst.stem('affection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e76bccd-37ce-40c2-8d62-971cc35c9912",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'play'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pst.stem('playing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e68b950-bde6-4d41-9214-652c7bd8e070",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'maximum'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pst.stem('maximum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947fb2f4-2d6c-4d6a-bdcb-d8089f05470d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "give:give\n",
      "giving:give\n",
      "given:given\n",
      "gave:gave\n"
     ]
    }
   ],
   "source": [
    "word_to_stem = ['give','giving','given','gave']\n",
    "for words in word_to_stem:\n",
    "    print(words+ ':' +pst.stem(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58882fa1-5acf-426a-8b79-341f037f3aec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "give:give\n",
      "giving:give\n",
      "given:given\n",
      "gaved:gave\n",
      "thinking:think\n",
      "loving:love\n"
     ]
    }
   ],
   "source": [
    "ds_to_stem = ['give','giving','given','gaved','thinking','loving']\n",
    "for words in ds_to_stem:\n",
    "  print(words+ ':' +pst.stem(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dddee419-8182-4500-8824-3c074ff59833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "give:giv\n",
      "giving:giv\n",
      "given:giv\n",
      "gave:gav\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import LancasterStemmer\n",
    "lst = LancasterStemmer()\n",
    "\n",
    "for words in word_to_stem:\n",
    "    print(words+':'+lst.stem(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00eec3eb-6bbf-4f76-a71e-1944ae02dd10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "give:give\n",
      "giving:give\n",
      "given:given\n",
      "gave:gave\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "sbst = SnowballStemmer('english')\n",
    "for words in word_to_stem:\n",
    "    print(words+':'+sbst.stem(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff15684-81e8-4584-9c64-64e21ad2d95a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'autobahn'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer = SnowballStemmer('german')\n",
    ">>> stemmer.stem(\"Autobahnen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f7af67-07a0-4862-a5fd-f8858d3c6990",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')   # optional but recommended\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99833a61-6298-47f6-b5ad-6280dd0e3add",
   "metadata": {},
   "source": [
    "# Lemmatization\n",
    "--> reduces words to their dictionary(lemma) form, considering meaning and  grammer.\n",
    "--> more accurate than stemming because it uses vocabulary and morphological analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a7fd14-5b92-4d3f-b487-4aa1881b2064",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "word_len = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "df98b275-63f6-4137-bef3-1df8c8add0a0",
   "metadata": {},
   "source": [
    "word_to_stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9543141-bba5-4d4d-b66d-f59b734efc3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "give:give\n",
      "giving:giving\n",
      "given:given\n",
      "gave:gave\n"
     ]
    }
   ],
   "source": [
    "for words in word_to_stem:\n",
    "    print(words+':'+word_len.lemmatize(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8179ac73-e31e-4a1c-8259-47675adcac71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2c1ea7-3a67-47b8-8a68-7ec9427a2300",
   "metadata": {},
   "source": [
    "# Stopwords\n",
    "--> definition:Commonly used words(e.g:\"the\",\"is\",\"in\") that are often removed in NLP tasks.\n",
    "--> Removing stopwords helps focus on meaningful content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8c56ae-77b2-484e-9dec-43cd5709e2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b96ac20-ad9f-470b-a781-cf0a79620938",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " \"he'd\",\n",
       " \"he'll\",\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " \"he's\",\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " \"i'd\",\n",
       " 'if',\n",
       " \"i'll\",\n",
       " \"i'm\",\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it'd\",\n",
       " \"it'll\",\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " \"i've\",\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she'd\",\n",
       " \"she'll\",\n",
       " \"she's\",\n",
       " 'should',\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " \"should've\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " \"they'd\",\n",
       " \"they'll\",\n",
       " \"they're\",\n",
       " \"they've\",\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " \"we'd\",\n",
       " \"we'll\",\n",
       " \"we're\",\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " \"we've\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " 'your',\n",
       " \"you're\",\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " \"you've\"]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550aa617-4a70-4d2e-b26c-739f2163517a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "198"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ace5f40-1d1b-4d32-97bb-3ccb4323757c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger_eng.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger_eng')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f38ce45-53f6-4a35-ba34-c38e87a8be68",
   "metadata": {},
   "source": [
    "# POS Tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f5bd80-3a6c-44c9-b05e-2608334b0791",
   "metadata": {},
   "source": [
    "--> definition: Assigns grammatical labels(noun,verb,adjective,etc) to each token in a sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abc0429-0631-4fc7-aec3-b258e6975c82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('The', 'DT'), ('quick', 'JJ'), ('brown', 'NN'), ('fox', 'NN'), ('jumps', 'VBZ'), ('over', 'IN'), ('the', 'DT'), ('lazy', 'JJ'), ('dog', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "sentence = \"The quick brown fox jumps over the lazy dog\"\n",
    "tokens = word_tokenize(sentence)\n",
    "pos_tags = nltk.pos_tag(tokens)\n",
    "\n",
    "print(pos_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42dcf378-f5a9-4c89-ba90-1dd9e618ecd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package maxent_ne_chunker_tab to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping chunkers\\maxent_ne_chunker_tab.zip.\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\words.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('maxent_ne_chunker_tab')\n",
    "nltk.download('words')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdadf754-8f37-4511-8fe0-e050c48b6309",
   "metadata": {},
   "source": [
    "# Named Entity Recognition(NER)\n",
    "--> Definition:Identifies and classifies entities in text (people,places,organizations,dates,etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659871e5-d1bf-4b60-b5c1-ade6d860e3d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  The/DT\n",
      "  (GSP US/NNP)\n",
      "  president/NN\n",
      "  stays/NNS\n",
      "  in/IN\n",
      "  the/DT\n",
      "  (ORGANIZATION WHITEHOUSE/NNP))\n"
     ]
    }
   ],
   "source": [
    "from nltk import ne_chunk\n",
    "NE_sent = \"The US president stays in the WHITEHOUSE\"\n",
    "NE_tokens = word_tokenize(NE_sent)\n",
    "NE_tags =nltk.pos_tag(NE_tokens)\n",
    "NE_NER =ne_chunk(NE_tags)\n",
    "\n",
    "print(NE_NER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa86048-6f84-4b12-9b52-0ae6dcb60785",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
